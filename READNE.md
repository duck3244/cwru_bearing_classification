# CWRU Bearing Fault Classification with PyTorch

ë² ì–´ë§ ê³ ì¥ ì§„ë‹¨ì„ ìœ„í•œ ë”¥ëŸ¬ë‹ ê¸°ë°˜ ë¶„ë¥˜ ì‹œìŠ¤í…œì…ë‹ˆë‹¤. Case Western Reserve University (CWRU) ë² ì–´ë§ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ì—¬ ì •ìƒ ìƒíƒœì™€ ë‹¤ì–‘í•œ ê³ ì¥ ìœ í˜•ì„ ë¶„ë¥˜í•©ë‹ˆë‹¤.

## ğŸ¯ í”„ë¡œì íŠ¸ ê°œìš”

ì´ í”„ë¡œì íŠ¸ëŠ” ë² ì–´ë§ì˜ ì§„ë™ ì‹ í˜¸ë¥¼ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ 4ê°€ì§€ ìƒíƒœë¥¼ ë¶„ë¥˜í•©ë‹ˆë‹¤:

- **Normal**: ì •ìƒ ìƒíƒœ
- **Ball Fault**: ë³¼ ê²°í•¨
- **Inner Race Fault**: ë‚´ë¥œ ê²°í•¨
- **Outer Race Fault**: ì™¸ë¥œ ê²°í•¨

## âœ¨ ì£¼ìš” ê¸°ëŠ¥

### 1. íŠ¹ì§• ì¶”ì¶œ
- **ì‹œê°„ ë„ë©”ì¸ íŠ¹ì§•**
  - í‰ê· , í‘œì¤€í¸ì°¨, RMS, í”¼í¬ê°’
  - ì²¨ë„(Kurtosis), ì™œë„(Skewness)
  - íŒŒí˜• ì¸ì, ì„í„ìŠ¤ ì¸ì
  - ì‹ í˜¸ ì—ë„ˆì§€

- **ì£¼íŒŒìˆ˜ ë„ë©”ì¸ íŠ¹ì§•**
  - FFT ê¸°ë°˜ íŒŒì›Œ ìŠ¤í™íŠ¸ëŸ¼
  - ì§€ë°° ì£¼íŒŒìˆ˜, ì£¼íŒŒìˆ˜ ì¤‘ì‹¬
  - ìŠ¤í™íŠ¸ëŸ¼ ì—”íŠ¸ë¡œí”¼

### 2. ë”¥ëŸ¬ë‹ ëª¨ë¸
- ë‹¤ì¸µ í¼ì…‰íŠ¸ë¡ (MLP) ì•„í‚¤í…ì²˜
- Batch Normalizationìœ¼ë¡œ ì•ˆì •ì ì¸ í•™ìŠµ
- Dropoutìœ¼ë¡œ ê³¼ì í•© ë°©ì§€
- Learning Rate Schedulerë¡œ ìµœì í™”

### 3. ì‹œê°í™”
- í•™ìŠµ ê³¡ì„  (Loss & Accuracy)
- í˜¼ë™ í–‰ë ¬ (Confusion Matrix)
- ë¶„ë¥˜ ì„±ëŠ¥ ë¦¬í¬íŠ¸

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
cwru_bearing_classification/
â”‚
â”œâ”€â”€ config.py                  # í”„ë¡œì íŠ¸ ì„¤ì • ë° í•˜ì´í¼íŒŒë¼ë¯¸í„°
â”œâ”€â”€ data_loader.py             # ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬
â”œâ”€â”€ feature_extraction.py      # íŠ¹ì§• ì¶”ì¶œ í•¨ìˆ˜
â”œâ”€â”€ dataset.py                 # PyTorch Dataset í´ë˜ìŠ¤
â”œâ”€â”€ model.py                   # ì‹ ê²½ë§ ëª¨ë¸ ì •ì˜
â”œâ”€â”€ trainer.py                 # í•™ìŠµ ë° í‰ê°€ ë¡œì§
â”œâ”€â”€ visualizer.py              # ê²°ê³¼ ì‹œê°í™”
â”œâ”€â”€ main.py                    # ë©”ì¸ ì‹¤í–‰ íŒŒì¼
â”‚
â”œâ”€â”€ data/                      # ë°ì´í„° ë””ë ‰í† ë¦¬
â”‚   â””â”€â”€ (CWRU .mat íŒŒì¼ë“¤)
â”‚
â”œâ”€â”€ models/                    # ì €ì¥ëœ ëª¨ë¸
â”‚   â””â”€â”€ best_model.pth
â”‚
â”œâ”€â”€ results/                   # ê²°ê³¼ ì´ë¯¸ì§€
â”‚   â”œâ”€â”€ training_history.png
â”‚   â””â”€â”€ confusion_matrix.png
â”‚
â”œâ”€â”€ requirements.txt           # íŒ¨í‚¤ì§€ ì˜ì¡´ì„±
â””â”€â”€ README.md                  # ì´ ë¬¸ì„œ
```

## ğŸ”§ ì„¤ì¹˜ ë°©ë²•

### 1. ê°€ìƒ í™˜ê²½ ìƒì„± (ì„ íƒì‚¬í•­)

```bash
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
```

### 2. í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜

```bash
pip install -r requirements.txt
```

**requirements.txt ë‚´ìš©:**
```
torch>=2.0.0
numpy>=1.24.0
pandas>=2.0.0
scikit-learn>=1.3.0
scipy>=1.11.0
matplotlib>=3.7.0
seaborn>=0.12.0
```

## ğŸš€ ì‚¬ìš© ë°©ë²•

### ê¸°ë³¸ ì‹¤í–‰

```bash
python main.py
```

### ë‹¨ê³„ë³„ ì‹¤í–‰

1. **ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬**
```python
from config import Config
from data_loader import CWRUDataLoader

config = Config()
data_loader = CWRUDataLoader(config)
X, y = data_loader.load_data()
```

2. **ëª¨ë¸ ìƒì„±**
```python
from model import BearingClassifier

model = BearingClassifier(
    input_size=X.shape[1],
    hidden_sizes=[128, 64, 32],
    num_classes=4,
    dropout=0.3
)
```

3. **í•™ìŠµ**
```python
from trainer import Trainer

trainer = Trainer(model, config)
trainer.train(train_loader, test_loader, epochs=50)
```

4. **í‰ê°€ ë° ì‹œê°í™”**
```python
from visualizer import Visualizer

visualizer = Visualizer(config)
visualizer.plot_training_history(trainer.history)
visualizer.plot_confusion_matrix(y_true, y_pred)
```

## ğŸ“Š ë°ì´í„°ì…‹

### CWRU ë² ì–´ë§ ë°ì´í„°ì…‹

- **ì¶œì²˜**: [Case Western Reserve University Bearing Data Center](https://engineering.case.edu/bearingdatacenter)
- **ìƒ˜í”Œë§ ë ˆì´íŠ¸**: 12,000 Hz
- **ìœˆë„ìš° í¬ê¸°**: 1,024 ìƒ˜í”Œ
- **í´ë˜ìŠ¤**: 4ê°œ (Normal, Ball, IR, OR)

### ë°ì´í„° êµ¬ì¡°

```
data/
â”œâ”€â”€ Normal_0.mat
â”œâ”€â”€ Ball_007.mat
â”œâ”€â”€ IR_007.mat
â””â”€â”€ OR_007.mat
```

### ì‹¤ì œ ë°ì´í„° ì‚¬ìš©í•˜ê¸°

`data_loader.py`ì˜ `_generate_sample_data()` í•¨ìˆ˜ë¥¼ ì‹¤ì œ .mat íŒŒì¼ ë¡œë”© ì½”ë“œë¡œ êµì²´í•˜ì„¸ìš”:

```python
def load_mat_file(self, filepath):
    """ì‹¤ì œ CWRU .mat íŒŒì¼ ë¡œë“œ"""
    mat_data = loadmat(filepath)
    # ë°ì´í„° í‚¤ëŠ” íŒŒì¼ë§ˆë‹¤ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ
    # ì˜ˆ: 'DE_time', 'FE_time' ë“±
    data = mat_data['DE_time'].flatten()
    return data
```

## ğŸ—ï¸ ëª¨ë¸ ì•„í‚¤í…ì²˜

### ê¸°ë³¸ êµ¬ì¡°

```
Input Layer (19 features)
    â†“
Dense Layer (128) + BatchNorm + ReLU + Dropout(0.3)
    â†“
Dense Layer (64) + BatchNorm + ReLU + Dropout(0.3)
    â†“
Dense Layer (32) + BatchNorm + ReLU + Dropout(0.3)
    â†“
Output Layer (4 classes)
```

### íŠ¹ì§• ë²¡í„° êµ¬ì„± (19ì°¨ì›)

**ì‹œê°„ ë„ë©”ì¸ (13ê°œ)**
- í‰ê· , í‘œì¤€í¸ì°¨, ìµœëŒ€ê°’, ìµœì†Œê°’, Peak-to-peak
- RMS, ì ˆëŒ€í‰ê· , í”¼í¬ê°’
- íŒŒí˜• ì¸ì, ì„í„ìŠ¤ ì¸ì
- ì²¨ë„, ì™œë„, ì‹ í˜¸ ì—ë„ˆì§€

**ì£¼íŒŒìˆ˜ ë„ë©”ì¸ (6ê°œ)**
- í‰ê·  íŒŒì›Œ, íŒŒì›Œ í‘œì¤€í¸ì°¨, ìµœëŒ€ íŒŒì›Œ
- ì§€ë°° ì£¼íŒŒìˆ˜, ì£¼íŒŒìˆ˜ ì¤‘ì‹¬, ìŠ¤í™íŠ¸ëŸ¼ ì—”íŠ¸ë¡œí”¼

## ğŸ“ˆ ê²°ê³¼

### ì˜ˆìƒ ì„±ëŠ¥

- **í•™ìŠµ ì •í™•ë„**: ~95-98%
- **ê²€ì¦ ì •í™•ë„**: ~92-96%
- **í…ŒìŠ¤íŠ¸ ì •í™•ë„**: ~90-95%

### ê²°ê³¼ íŒŒì¼

í•™ìŠµ ì™„ë£Œ í›„ ë‹¤ìŒ íŒŒì¼ë“¤ì´ ìƒì„±ë©ë‹ˆë‹¤:

- `models/best_model.pth`: ìµœê³  ì„±ëŠ¥ ëª¨ë¸
- `results/training_history.png`: í•™ìŠµ ê³¡ì„ 
- `results/confusion_matrix.png`: í˜¼ë™ í–‰ë ¬

## âš™ï¸ ì„¤ì • ë³€ê²½

`config.py` íŒŒì¼ì—ì„œ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```python
class Config:
    # ëª¨ë¸ êµ¬ì¡°
    HIDDEN_SIZES = [128, 64, 32]  # íˆë“  ë ˆì´ì–´ í¬ê¸°
    DROPOUT = 0.3                  # ë“œë¡­ì•„ì›ƒ ë¹„ìœ¨
    
    # í•™ìŠµ íŒŒë¼ë¯¸í„°
    BATCH_SIZE = 32                # ë°°ì¹˜ í¬ê¸°
    LEARNING_RATE = 0.001          # í•™ìŠµë¥ 
    EPOCHS = 50                    # ì—í¬í¬ ìˆ˜
    WEIGHT_DECAY = 1e-5            # ê°€ì¤‘ì¹˜ ê°ì‡ 
    
    # ë°ì´í„° íŒŒë¼ë¯¸í„°
    WINDOW_SIZE = 1024             # ìœˆë„ìš° í¬ê¸°
    SAMPLING_RATE = 12000          # ìƒ˜í”Œë§ ë ˆì´íŠ¸
```

## ğŸ”¬ ì„±ëŠ¥ í–¥ìƒ íŒ

### 1. ë°ì´í„° ì¦ê°•
- ìœˆë„ìš° ìŠ¬ë¼ì´ë”©ìœ¼ë¡œ ë” ë§ì€ ìƒ˜í”Œ ìƒì„±
- ë…¸ì´ì¦ˆ ì¶”ê°€ë¡œ robustí•œ ëª¨ë¸ í•™ìŠµ

### 2. ëª¨ë¸ íŠœë‹
- íˆë“  ë ˆì´ì–´ ìˆ˜ì™€ í¬ê¸° ì¡°ì •
- Dropout ë¹„ìœ¨ ë³€ê²½
- Learning Rate ì¡°ì •

### 3. íŠ¹ì§• ì—”ì§€ë‹ˆì–´ë§
- ì¶”ê°€ ì‹œê°„/ì£¼íŒŒìˆ˜ ë„ë©”ì¸ íŠ¹ì§•
- Wavelet ë³€í™˜ íŠ¹ì§•
- Envelope ë¶„ì„

### 4. ì•™ìƒë¸” ë°©ë²•
- ì—¬ëŸ¬ ëª¨ë¸ì˜ ì˜ˆì¸¡ ê²°í•©
- K-Fold êµì°¨ ê²€ì¦

## ğŸ› íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### CUDA ë©”ëª¨ë¦¬ ë¶€ì¡±
```python
# config.pyì—ì„œ ë°°ì¹˜ í¬ê¸° ê°ì†Œ
BATCH_SIZE = 16  # 32ì—ì„œ 16ìœ¼ë¡œ
```

### ê³¼ì í•© ë°œìƒ
```python
# Dropout ë¹„ìœ¨ ì¦ê°€
DROPOUT = 0.5  # 0.3ì—ì„œ 0.5ë¡œ

# Weight Decay ì¦ê°€
WEIGHT_DECAY = 1e-4  # 1e-5ì—ì„œ 1e-4ë¡œ
```

### í•™ìŠµì´ ëŠë¦° ê²½ìš°
```python
# í•™ìŠµë¥  ì¦ê°€
LEARNING_RATE = 0.01  # 0.001ì—ì„œ 0.01ë¡œ

# GPU ì‚¬ìš© í™•ì¸
print(torch.cuda.is_available())
```

## ğŸ“š ì°¸ê³  ìë£Œ

- [CWRU Bearing Data Center](https://engineering.case.edu/bearingdatacenter)
- [PyTorch Documentation](https://pytorch.org/docs/stable/index.html)
- [Scikit-learn Documentation](https://scikit-learn.org/stable/)

---
